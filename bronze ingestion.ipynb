{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfe46360-d94d-4a2a-a299-5521e55f5bae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read CRM CSV files separately into DataFrames"
    }
   },
   "outputs": [],
   "source": [
    "# Read each CRM CSV file separately into its own DataFrame\n",
    "cust_info_path = '/Volumes/workspace/bronze/raw_resources/crm/cust_info.csv'\n",
    "prd_info_path = '/Volumes/workspace/bronze/raw_resources/crm/prd_info.csv'\n",
    "sales_details_path = '/Volumes/workspace/bronze/raw_resources/crm/sales_details.csv'\n",
    "\n",
    "cust_info_df = spark.read.csv(cust_info_path, header=True, inferSchema=True)\n",
    "prd_info_df = spark.read.csv(prd_info_path, header=True, inferSchema=True)\n",
    "sales_details_df = spark.read.csv(sales_details_path, header=True, inferSchema=True)\n",
    "\n",
    "display(cust_info_df)\n",
    "display(prd_info_df)\n",
    "display(sales_details_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9b85933-3a86-4c84-9d99-b3bfb8aff394",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write CRM DataFrames to Bronze tables"
    }
   },
   "outputs": [],
   "source": [
    "# Read each ERP CSV file separately into its own DataFrame\n",
    "erp_cust_az12_path = '/Volumes/workspace/bronze/raw_resources/erp/CUST_AZ12.csv'\n",
    "erp_loc_a101_path = '/Volumes/workspace/bronze/raw_resources/erp/LOC_A101.csv'\n",
    "erp_px_cat_g1v2_path = '/Volumes/workspace/bronze/raw_resources/erp/PX_CAT_G1V2.csv'\n",
    "\n",
    "erp_cust_az12_df = spark.read.csv(erp_cust_az12_path, header=True, inferSchema=True)\n",
    "erp_loc_a101_df = spark.read.csv(erp_loc_a101_path, header=True, inferSchema=True)\n",
    "erp_px_cat_g1v2_df = spark.read.csv(erp_px_cat_g1v2_path, header=True, inferSchema=True)\n",
    "\n",
    "display(erp_cust_az12_df)\n",
    "display(erp_loc_a101_df)\n",
    "display(erp_px_cat_g1v2_df)\n",
    "\n",
    "# Write each ERP DataFrame to a Unity Catalog table in Bronze schema with source-system prefix\n",
    "erp_cust_az12_df.write.mode('overwrite').saveAsTable('workspace.bronze.erp_cust_az12')\n",
    "erp_loc_a101_df.write.mode('overwrite').saveAsTable('workspace.bronze.erp_loc_a101')\n",
    "erp_px_cat_g1v2_df.write.mode('overwrite').saveAsTable('workspace.bronze.erp_px_cat_g1v2')\n",
    "\n",
    "# Verify writes by reading the tables\n",
    "display(spark.table('workspace.bronze.erp_cust_az12'))\n",
    "display(spark.table('workspace.bronze.erp_loc_a101'))\n",
    "display(spark.table('workspace.bronze.erp_px_cat_g1v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "275ff9ce-c912-4e7a-ab06-2b30fbd98b80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read each ERP CSV file separately into its own DataFrame\n",
    "erp_cust_az12_path = '/Volumes/workspace/bronze/raw_resources/erp/CUST_AZ12.csv'\n",
    "erp_loc_a101_path = '/Volumes/workspace/bronze/raw_resources/erp/LOC_A101.csv'\n",
    "erp_px_cat_g1v2_path = '/Volumes/workspace/bronze/raw_resources/erp/PX_CAT_G1V2.csv'\n",
    "\n",
    "erp_cust_az12_df = spark.read.csv(erp_cust_az12_path, header=True, inferSchema=True)\n",
    "erp_loc_a101_df = spark.read.csv(erp_loc_a101_path, header=True, inferSchema=True)\n",
    "erp_px_cat_g1v2_df = spark.read.csv(erp_px_cat_g1v2_path, header=True, inferSchema=True)\n",
    "\n",
    "display(erp_cust_az12_df)\n",
    "display(erp_loc_a101_df)\n",
    "display(erp_px_cat_g1v2_df)\n",
    "\n",
    "# Write each ERP DataFrame to a Unity Catalog table in Bronze schema with source-system prefix\n",
    "erp_cust_az12_df.write.mode('overwrite').saveAsTable('workspace.bronze.erp_cust_az12')\n",
    "erp_loc_a101_df.write.mode('overwrite').saveAsTable('workspace.bronze.erp_loc_a101')\n",
    "erp_px_cat_g1v2_df.write.mode('overwrite').saveAsTable('workspace.bronze.erp_px_cat_g1v2')\n",
    "\n",
    "# Verify writes by reading the tables\n",
    "display(spark.table('workspace.bronze.erp_cust_az12'))\n",
    "display(spark.table('workspace.bronze.erp_loc_a101'))\n",
    "display(spark.table('workspace.bronze.erp_px_cat_g1v2'))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
