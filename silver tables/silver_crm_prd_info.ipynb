{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c81881-b3c2-4c45-85f1-cf26f4a1c7e7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reusable Data Cleaning Functions for Product Info"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from typing import Dict, Optional\n",
    "from itertools import chain\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. HELPER FUNCTIONS (Matches your strict definitions)\n",
    "# ==============================================================================\n",
    "\n",
    "def create_map_from_dict(mapping: Dict[str, str]):\n",
    "    return F.create_map([F.lit(x) for x in chain(*mapping.items())])\n",
    "\n",
    "def trim_all_string_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Optimized trimming (O(1) overhead)\"\"\"\n",
    "    str_cols = {f.name for f in df.schema.fields if isinstance(f.dataType, StringType)}\n",
    "    return df.select(\n",
    "        *[F.trim(F.col(c)).alias(c) if c in str_cols else F.col(c) for c in df.columns]\n",
    "    )\n",
    "\n",
    "def standardize_key(df: DataFrame, col: str, new_col: str) -> DataFrame:\n",
    "    clean_col = F.upper(F.regexp_replace(F.col(col), '[^A-Za-z0-9]', ''))\n",
    "    return df.withColumn(new_col, clean_col)\n",
    "\n",
    "def normalize_product_line(df: DataFrame, col: str) -> DataFrame:\n",
    "    # 1. Externalize the dictionary for readability\n",
    "    line_rules = {'R': 'Road', 'S': 'Sport', 'M': 'Mountain'}\n",
    "    map_col = create_map_from_dict(line_rules)\n",
    "    return df.withColumn(col, F.coalesce(map_col[F.upper(F.col(col))], F.col(col)))\n",
    "\n",
    "def flag_invalid_numeric(df: DataFrame, col: str, min_val: Optional[int] = None, max_val: Optional[int] = None) -> DataFrame:\n",
    "    \"\"\"CRITICAL FIX: Creates a flag ('is_valid_...') instead of filtering.\"\"\"\n",
    "    col_val = F.col(col).cast('int')\n",
    "    is_valid = col_val.isNotNull()\n",
    "    \n",
    "    if min_val is not None:\n",
    "        is_valid = is_valid & (col_val >= min_val)\n",
    "    if max_val is not None:\n",
    "        is_valid = is_valid & (col_val <= max_val)\n",
    "        \n",
    "    return df.withColumn(f\"is_valid_{col}\", is_valid)\n",
    "\n",
    "def flag_invalid_date(df: DataFrame, col: str) -> DataFrame:\n",
    "    \"\"\"CRITICAL FIX: Creates a flag instead of filtering.\"\"\"\n",
    "    return df.withColumn(f\"is_valid_{col}\", F.col(col).isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "809291a0-9bbd-4906-b4b6-7cd2ef0fdb58",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Clean and Write Silver Product Info Table"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from typing import Dict\n",
    "from itertools import chain\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def create_map_from_dict(mapping: Dict[str, str]):\n",
    "    \"\"\"\n",
    "    Converts a Python Dictionary into a Spark Map column.\n",
    "    WHY: Decouples business rules (the dict) from the execution logic.\n",
    "    \"\"\"\n",
    "    return F.create_map([F.lit(x) for x in chain(*mapping.items())])\n",
    "\n",
    "def trim_all_string_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Trims whitespace from all string columns in one pass.\n",
    "    WHY: ' DAG Explosion'. Doing this in a loop kills performance. \n",
    "    This list comprehension does it in O(1) planning time.\n",
    "    \"\"\"\n",
    "    str_cols = {f.name for f in df.schema.fields if isinstance(f.dataType, StringType)}\n",
    "    return df.select(\n",
    "        *[F.trim(F.col(c)).alias(c) if c in str_cols else F.col(c) for c in df.columns]\n",
    "    )\n",
    "\n",
    "def standardize_key(df: DataFrame, col: str, new_col: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans keys by uppercasing and removing special characters.\n",
    "    e.g., \"Bike-123\" -> \"BIKE123\"\n",
    "    \"\"\"\n",
    "    clean_col = F.upper(F.regexp_replace(F.col(col), '[^A-Za-z0-9]', ''))\n",
    "    return df.withColumn(new_col, clean_col)\n",
    "\n",
    "def normalize_product_line(df: DataFrame, col: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Maps codes (R, S, M) to full names (Road, Sport, Mountain).\n",
    "    \"\"\"\n",
    "    line_rules = {'R': 'Road', 'S': 'Sport', 'M': 'Mountain', 'T': 'Touring'}\n",
    "    map_col = create_map_from_dict(line_rules)\n",
    "    # Coalesce keeps the original value if the code isn't found in the map\n",
    "    return df.withColumn(col, F.coalesce(map_col[F.upper(F.col(col))], F.col(col)))\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. MAIN PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "def process_crm_prd_info(bronze_table: str, silver_table: str):\n",
    "    print(f\"Starting processing for {silver_table}...\")\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # STEP 1: READ\n",
    "    # --------------------------------------------------------------------------\n",
    "    # WHAT: Load the raw bronze data.\n",
    "    df_bronze = spark.table(bronze_table)\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # STEP 2: TRANSFORM PIPELINE\n",
    "    # --------------------------------------------------------------------------\n",
    "    # WHAT: Chain operations cleanly using .transform().\n",
    "    # WHY:  Avoids intermediate variables (df1, df2, df3) and makes flow readable.\n",
    "    df_silver = (df_bronze\n",
    "        # A. Clean Whitespace\n",
    "        # WHY: \" Road \" and \"Road\" should be treated as the same.\n",
    "        .transform(trim_all_string_columns)\n",
    "        \n",
    "        # B. Standardize Key (Part 1: Clean Chars)\n",
    "        # WHAT: Removes hyphens/underscores. \"BIKE-123\" -> \"BIKE123\"\n",
    "        .transform(lambda df: standardize_key(df, 'prd_key', 'std_prd_key'))\n",
    "        \n",
    "        # C. Truncate Key (Part 2: 4-Char Limit)\n",
    "        # WHAT: Takes first 4 characters. \"BIKE123\" -> \"BIKE\"\n",
    "        # WHY:  Matches the 'std_ID' format in the ERP system for joining.\n",
    "        .withColumn('std_prd_key', F.col('std_prd_key').substr(1, 4))\n",
    "        \n",
    "        # D. Business Logic\n",
    "        # WHAT: Expand 'R' -> 'Road'.\n",
    "        .transform(lambda df: normalize_product_line(df, 'prd_line'))\n",
    "    )\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # STEP 3: PROJECTION (The Contract)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # WHAT: Explicitly select and rename columns for the Silver Schema.\n",
    "    # WHY:  1. Renaming here is cleaner than using 10 .withColumnRenamed calls.\n",
    "    #       2. Drops all unused columns (like the original dirty 'prd_key').\n",
    "    df_final = df_silver.select(\n",
    "        F.col(\"prd_id\").alias(\"product_id\"),\n",
    "        F.col(\"prd_key\").alias(\"product_key\"),      # Keep original for audit\n",
    "        F.col(\"std_prd_key\"),                       # The new Join Key (4 chars)\n",
    "        F.col(\"prd_nm\").alias(\"product_name\"),\n",
    "        F.col(\"prd_cost\").alias(\"product_cost\"),\n",
    "        F.col(\"prd_line\").alias(\"product_line\"),\n",
    "        F.col(\"prd_start_dt\").alias(\"start_date\"),\n",
    "        F.col(\"prd_end_dt\").alias(\"end_date\")\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # STEP 4: FILTER (Quality Control)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # WHAT: Drop rows where the Key is invalid.\n",
    "    # WHY:  If the key isn't 4 chars, the Join to Gold will fail or be wrong.\n",
    "    #       Better to drop it here than pollute the Gold table.\n",
    "    df_final = df_final.filter(\n",
    "        F.col(\"std_prd_key\").isNotNull() & (F.length(F.col(\"std_prd_key\")) == 4)\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # STEP 5: WRITE\n",
    "    # --------------------------------------------------------------------------\n",
    "    # WHAT: Overwrite the target table.\n",
    "    # WHY:  Ensures Silver is an exact clean copy of the latest Bronze data.\n",
    "    df_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(silver_table)\n",
    "    \n",
    "    print(f\"Successfully wrote to {silver_table}\")\n",
    "    display(spark.table(silver_table))\n",
    "\n",
    "# ==============================================================================\n",
    "# Execution\n",
    "# ==============================================================================\n",
    "process_crm_prd_info('workspace.bronze.crm_prd_info', 'workspace.silver.crm_prd_info')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2353386082755375,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_crm_prd_info",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
